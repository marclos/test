---
title: "LA County Covid-19"
author: "Marc Los Huertos"
date: "3/28/2020"
output: ioslides_presentation 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, options(scipen=999))
```

# Introduction

- Human endeavors ahd human health
- Covid-19 lessons for sustainability in agriculture
- Do other zoonotic diseases follow patterns of Covid-19?


<div class="notes">

All human endeavors rely on human health -- in fact, our economic system is quite vulnerable to human disease. 

- How can we learn from the Covid-19 pandemic to think about the role of sustainability in agriculture?

- Do other zoonotic diseases follow patterns in Covid-19?

- Should we re-design the food system to reduce the vulnerability to zoonosis?

</div>

## Case Study -- LA County

- By focusing in on one region, we can better appreciate both our response and the larger context.

- Disclaimer

Not peer reviewed work and well outside my typical professional work.

- Data Source

[Data hosted on github](https://github.com/CSSEGISandData/COVID-19), entitled Novel Coronavirus (COVID-19) Cases and provided by Johns Hopkins University, Center for Systems Science and Engineering.

# Work flow

- Combine Daily Situational Report into one dataframe

- Time consumig coding because of inconsisent source data formatting

```{r, echo=FALSE, results='hide', message=FALSE}
# download and read csvs
#I am using project connect to the gibhub site and pull into my own project. I can't push, but that's fine. 

# create list of csv
library(readr)
library(dplyr)

path = "~/github/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/" 

filepath <- list.files(path = path, pattern = "*.csv", full.names = T);
files <- list.files(path = path, pattern = "*.csv", full.names = F);
files = substring(files, 1, 10)
files = data.frame(files, filepath)
Daily = data.frame(NA)
for(i in 1:c(nrow(files)-0)){
   tmp = paste(files[i,2])
   tmp2 <- read.csv(tmp)
   tmp2$Date = paste(files[i,1])
   tmp2[] <- lapply(tmp2, as.character)

Daily = dplyr::bind_rows(Daily, tmp2)
}
  

```

- Subset Los Angeles County

## Early Records in Pandemic 
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap ="Early Records of Confirmed Cases of Covid-19 in LA County"}
#str(Daily)
#subset(Daily, FIPS==c(6037))
LA = subset(Daily, subset=(Admin2 == "Los Angeles" | Province.State == "Los Angeles, CA"))
LA$Confirmed=as.numeric(LA$Confirmed)
LA$Date= as.Date(as.character(LA$Date), format='%m-%d-%Y')
plot(Confirmed~Date, data=LA, las=1, ylim=c(0,18), ty='b')
```

## Dramatic Changes in March
- Note the missing data early in LA County
```{r, echo=FALSE, fig.cap='Confirmed Cases in Los Angeles County (Source JHU-CSSE)'}

plot(Confirmed~Date, data=LA, las=1, pch=20)
```


## Using LA County Public Health Data 

I found press releases by the County to have some of the missing data:

- 3/09/2020  = 16 cases (github reported 14)
- 3/10/2020  = 17 cases, but missing LB and Pasadena
- 3/11/2020  = 27 cases
- 3/12/2020  = 32 cases
- 3/13/2020  = 40 cases
- 3/14/2020  = 53 cases
- 3/15/2020  = 69 cases
- 3/16/2020  = 94 cases
- 3/17/2020  = 144 cases
- 3/18/2020  = 190 cases
- 3/19/2020  = 231 cases
- 3/20/2020  = 292 cases
- 3/21/2020  = 351 cases
- 3/22/2020  = 409 cases (corrected as 407 on the 23rd, same as github)
- 3/23/2020  = 536 cases (90 hospitalized) same as github

```{r countydata, echo=FALSE}
county = data.frame(Date = as.Date(c("2020-03-10", "2020-03-11", "2020-03-12", "2020-03-13", "2020-03-14", "2020-03-15", "2020-03-16", "2020-03-17", "2020-03-18", "2020-03-19", "2020-03-20", "2020-03-21")), Confirmed = c( 17, 27, 32, 40, 53, 69, 94, 144, 190, 231, 292, 351))

LA = bind_rows(LA, county)

```

## Complete Dataset

```{r, echo=FALSE, fig.cap='Confirmed Cases in Los Angeles County (Source JHU-CSSE and LA County Public Health)'}
plot(Confirmed~Date, data=LA, las=1, pch=20)
```

## Determine Doubling Rate

- Doubling rate is an estimate of how time (days in our case) are the number of confirmed cases doubled 

- An analysis is based on the slope of the natural log of the confirmed cases

- But when should we begin the analysis, i.e. when does the epidemic begin?


```{r, echo=FALSE, results='hide'}
LA$lnConfirmed = log(LA$Confirmed)
LA.lm.bad = lm(lnConfirmed~Date, data=LA)
LA.lm.bad.sum = summary(LA.lm.bad)
LA.lm.bad.sum$r.squared 
LA.lm = lm(lnConfirmed~Date, data=LA[-c(1:32),])
LA.lm.sum = summary(LA.lm)
# names(LA.lm.sum)
dr.bad = as.vector(round(log(2)/LA.lm.bad$coef[2],1)); dr.bad
dr = as.vector(round(log(2)/LA.lm$coef[2],1)); dr

# Confidence Intervals
conf_int <- predict(LA.lm,LA, interval="confidence")
LA = cbind(LA, conf_int); head(LA)
```

## Testing when the epidemic began?

- As it turns out the first 31 days there is only one confirmed infection -- so, I'll begin the analysis on the 32nd day, there were 7 infections. 

- Using the r^2^ to evaluate the models

  * Model 1: r^2^ = `r round(LA.lm.bad.sum$r.squared, 3)`
  * Model 2: r^2^ = `r round(LA.lm.sum$r.squared, 3)`

- Doubling rate = log[2]/slope (growth rate)

# 

```{r, echo=FALSE, fig.cap ='Confirm Cases in Los Angeles County and Estimated Doubling Rates'}

plot(lnConfirmed ~ Date, data=LA, las=1, ylab="ln(Confirmed)")
abline(coef(LA.lm), col='darkred', lwd=1.4)
abline(coef(LA.lm.bad), col='purple')
text(as.Date("2020-02-18"), 1.8,paste("Doubling Rate =", dr.bad), col='purple')
text(as.Date("2020-03-08"), 5.1, paste("Doubling Rate =", dr), col='darkred')


```

## Policy Lag Times

```{r echo=FALSE, results='hide', fig.cap='Predicted Number of Covid-19 Cases in Los Angeles', warning=FALSE, message=FALSE}

plot(lnConfirmed ~ Date, data=LA, las=1, xlim=c(as.Date('2020-02-01'), as.Date('2020-04-17')), pch=20,
ylim=c(0,13), ylab="ln(Confirmed)")
lines(LA$Date, LA$fit, col='darkred', lwd=1.4)
lines(LA$Date, LA$upr, col='darkorange', lwd=1, lty=2)
lines(LA$Date, LA$lwr, col='darkorange', lwd=1, lty=2)

library(tidyverse)
library(lubridate)
new_dates <- tibble(Date=ymd(c('2020-04-03','2020-04-10', '2020-04-17', '2020-04-24', '2020-05-01')))
pred_vals <- predict(LA.lm,new_dates, interval="predict")
prediction =cbind(new_dates, pred_vals); prediction

lines(prediction$Date, prediction$fit, col='red', lwd=1.4)
lines(prediction$Date, prediction$upr, col='red', lwd=1, lty=2)
lines(prediction$Date, prediction$lwr, col='red', lwd=1, lty=2)

legend(as.Date('2020-02-01'), 6, legend=c("Best Fit Line", "Confidence Intervals", "Prediction", "Prediction Intervals"), lwd=1.4, col=c("darkred", "darkorange", "red", "red"), lty=c(1,2,1,2), cex=.6, bty="n") 

abline(h=prediction[1, 2], col="darkgreen")
abline(h=prediction[2, 2], col="blue")
abline(h=prediction[3, 2], col="purple")

text(as.Date('2020-03-01'), prediction[1, 2], paste("Confirmed =", round(exp(prediction[1, 2]),-1)), col='darkgreen', pos=1) 

text(as.Date('2020-03-01'), prediction[2, 2], paste("Confirmed =", round(exp(prediction[2, 2]),-1)), col='blue', pos=1)

text(as.Date('2020-03-01'), prediction[3, 2], paste("Confirmed =", round(exp(prediction[3, 2]),-1)), col='purple', pos=1) 

rect(as.Date('2020-03-19'),5, as.Date('2020-04-03'), prediction[1, 2], border=T)

```

##  April 3rd -- Two Weeks of After Newsome Order

- County will have approximately `r round(exp(pred_vals[1]),-1)` confirmed cases.

- Predictions have changed with more data:

 - March 25th 6170
 - March 26th 6620
 - March 27th 6810
 - March 28th 7230
 - March 29th 7190

# Changes in Doubling Rate

- Control of doubling rate is key to 'flattening the curve'.

- Reducing contact between susceptables in the key for that process. 

- SIR, SEIR, and SEIRS models used to explore various hypotheses

## Hospital and ICU Capacity

- California has 2.1 beds per 1,000 people

- With approximately 10.6 million residents, there are approximately `r (totalbeds=2.1/1000*10.6e6)` beds in the county. 

- Estimated 50% occupancy rate. 

- Number of available beds = `r (beds= totalbeds*.50)` 

```{r, echo=FALSE, results='hide'}
BedsByConfirmed = beds/.2; BedsByConfirmed
beddate = (log(BedsByConfirmed)-coef(LA.lm)[1])/coef(LA.lm)[2]; beddate
as.numeric(as.Date('1970-01-01')) # where is the origin

Bdate = as.Date(beddate, origin = "1970-01-01"); Bdate
Bdate2 = format(Bdate,"%m/%d"); Bdate2
```

- assume about 20% of the confirmed cases need hospital beds

## Estimated date of hospital bed shortage

- Thus, LA County will run out of beds on `r Bdate2`. 

- Model is missing is the category of 'recovered'. After 20 days hospitalized patients will either be in recovery (and can go home) or have died. Thus, a worst case scenario. 

- According to the LA Times, there are roughly 200 ICU beds in the county. I think about 5% of these who get sick need access to ICU. Probably an even more serious issue.

#

```{r bedshortage, echo=FALSE, cap.fig='Predicted Date the Available Hospital Beds will be Exceeded'}
# Projected values
options(scipen=5)

plot(Confirmed ~ Date, data=LA, las=1, yaxt='none', ylab="Confirmed (in thousands)", pch=20,
xlim=c(as.Date('2020-03-01'), as.Date('2020-04-28')), ylim=c(0, exp(max(prediction$upr[4]))))

axis(2, at=seq(0,1500000,500000), labels = c("0", "500", "1,000", "1,500"), las=2)
#axis(2, seq(0,1.5,.5),las=1, cex.axis=1)
points(prediction$Date, exp(prediction$fit), pch=20, col='red')
# Error Bars

arrows(x0=prediction$Date, y0=exp(prediction$fit), y1=exp(prediction$upr), code=2, col="red", lwd=.5, angle = 90, length=.03)
arrows(x0=prediction$Date, y0=exp(prediction$fit), y1=exp(prediction$lwr), code=2, col="red", lwd=.5, angle = 90, length=.03)

arrows(x0= as.Date(Bdate), y0 = 1000000, y1= 0, length = 0.15, angle = 20, code = 2, col = 'darkgoldenrod', lwd = 1)
text(as.Date(Bdate), 1000000, "County Bed Capacity Exceeded", pos=2, col='darkgoldenrod')

```


## Testing for an Nonlinear Growth Rate

- Is the doubling rate changing, i.e. non-linear?

- For example, Los Angeles reported a value of 1804 on the 28th of March. Was this within my confidence intervals?

```{r testingnewvalues, echo=FALSE, results='hide'}
test = data.frame(Date = max(LA$Date), Confirmed=LA$Confirmed[LA$Date==max(LA$Date)]); test

tested <- predict(LA.lm, test, interval="confidence");
result = cbind(test, logConfirmed = log(test$Confirmed), lwr = tested[,2], upr = tested[,3])
#LA = cbind(LA, conf_int); head(LA)

```

With this simple analysis, I obtained the following results: 

```{r, echo=FALSE}
print(result)
```


- Based on this, I suspect we are still well within the model expectations and there is no hint of flattening.

# The End

